{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basics of MLP\n",
    "- Objective: create vanilla neural networks (i.e., Multilayer perceptrons) for simple regression/classification tasks with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Structures\n",
    "- Each MLP model is consisted of one input layer, several hidden layers, and one output layer\n",
    "- Number of neurons in each layer is not limited\n",
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net.jpeg\" style=\"width: 300px\"/>\n",
    "<br>\n",
    "<center>**MLP with one hidden layer**</center>\n",
    "- Number of input neurons: 3\n",
    "- Number of hidden neurons: 4\n",
    "- Number of output neurons: 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://cs231n.github.io/assets/nn1/neural_net2.jpeg\" style=\"width: 500px\"/>\n",
    "<br>\n",
    "<center>**MLP with two hidden layers**</center>\n",
    "- Number of input neurons: 3\n",
    "- Number of hidden neurons: (4, 4)\n",
    "- Number of output neurons: 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for Regression tasks\n",
    "- When the target (**y**) is continuous (real)\n",
    "- For loss function and evaluation metric, mean squared error (MSE) is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "- Boston housing dataset has total 506 data instances (404 training & 102 test)\n",
    "- 13 attributes (features) to predict \"the median values of the houses at a location\"\n",
    "- Doc: https://keras.io/datasets/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "(102, 13)\n",
      "(404,)\n",
      "(102,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a model\n",
    "- Keras model object can be created with Sequential class\n",
    "- At the outset, the model is empty per se. It is completed by **'adding'** additional layers and compilation\n",
    "- Doc: https://keras.io/models/sequential/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Adding layers\n",
    "- Keras layers can be **added** to the model\n",
    "- Adding layers are like stacking lego blocks one by one\n",
    "- Doc: https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (13,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to the above code block\n",
    "model.add(Dense(10, input_shape = (13,), activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, loss = 'mean_squared_error', metrics = ['mse'])    # for regression problems, mean squared error (MSE) is often employed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 622\n",
      "Trainable params: 622\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples\n",
      "Epoch 1/100\n",
      "404/404 [==============================] - 1s 1ms/sample - loss: 293.4696 - mse: 293.4696\n",
      "Epoch 2/100\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 86.2438 - mse: 86.2438\n",
      "Epoch 3/100\n",
      "404/404 [==============================] - 0s 92us/sample - loss: 85.2770 - mse: 85.2770\n",
      "Epoch 4/100\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 84.9303 - mse: 84.9303\n",
      "Epoch 5/100\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 84.9691 - mse: 84.9691\n",
      "Epoch 6/100\n",
      "404/404 [==============================] - 0s 71us/sample - loss: 85.5498 - mse: 85.5498\n",
      "Epoch 7/100\n",
      "404/404 [==============================] - 0s 77us/sample - loss: 84.7038 - mse: 84.7038\n",
      "Epoch 8/100\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 84.8785 - mse: 84.8785\n",
      "Epoch 9/100\n",
      "404/404 [==============================] - 0s 102us/sample - loss: 85.1919 - mse: 85.1919\n",
      "Epoch 10/100\n",
      "404/404 [==============================] - 0s 98us/sample - loss: 84.9104 - mse: 84.9104\n",
      "Epoch 11/100\n",
      "404/404 [==============================] - 0s 62us/sample - loss: 85.0132 - mse: 85.0132\n",
      "Epoch 12/100\n",
      "404/404 [==============================] - 0s 58us/sample - loss: 85.0507 - mse: 85.0507\n",
      "Epoch 13/100\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 85.3224 - mse: 85.3224\n",
      "Epoch 14/100\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 85.4582 - mse: 85.4582\n",
      "Epoch 15/100\n",
      "404/404 [==============================] - 0s 50us/sample - loss: 84.9235 - mse: 84.9235\n",
      "Epoch 16/100\n",
      "404/404 [==============================] - 0s 68us/sample - loss: 84.9555 - mse: 84.9555\n",
      "Epoch 17/100\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 84.9957 - mse: 84.9957\n",
      "Epoch 18/100\n",
      "404/404 [==============================] - 0s 57us/sample - loss: 85.2113 - mse: 85.2113\n",
      "Epoch 19/100\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 85.3171 - mse: 85.3171\n",
      "Epoch 20/100\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 85.3292 - mse: 85.3292\n",
      "Epoch 21/100\n",
      "404/404 [==============================] - 0s 82us/sample - loss: 85.9427 - mse: 85.9427\n",
      "Epoch 22/100\n",
      "404/404 [==============================] - 0s 70us/sample - loss: 85.1017 - mse: 85.1017\n",
      "Epoch 23/100\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 86.0888 - mse: 86.0888\n",
      "Epoch 24/100\n",
      "404/404 [==============================] - 0s 87us/sample - loss: 86.2904 - mse: 86.2904\n",
      "Epoch 25/100\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 84.7299 - mse: 84.7299\n",
      "Epoch 26/100\n",
      "404/404 [==============================] - 0s 65us/sample - loss: 84.7338 - mse: 84.7338\n",
      "Epoch 27/100\n",
      "404/404 [==============================] - 0s 46us/sample - loss: 85.0521 - mse: 85.0521\n",
      "Epoch 28/100\n",
      "404/404 [==============================] - 0s 42us/sample - loss: 84.7958 - mse: 84.7958\n",
      "Epoch 29/100\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 85.7457 - mse: 85.7457\n",
      "Epoch 30/100\n",
      "404/404 [==============================] - 0s 83us/sample - loss: 85.1651 - mse: 85.1651\n",
      "Epoch 31/100\n",
      "404/404 [==============================] - 0s 75us/sample - loss: 85.0810 - mse: 85.0810\n",
      "Epoch 32/100\n",
      "404/404 [==============================] - 0s 77us/sample - loss: 85.3992 - mse: 85.3992\n",
      "Epoch 33/100\n",
      "404/404 [==============================] - 0s 51us/sample - loss: 85.8091 - mse: 85.8091\n",
      "Epoch 34/100\n",
      "404/404 [==============================] - 0s 66us/sample - loss: 85.0205 - mse: 85.0205\n",
      "Epoch 35/100\n",
      "404/404 [==============================] - 0s 69us/sample - loss: 84.8559 - mse: 84.8559\n",
      "Epoch 36/100\n",
      "404/404 [==============================] - 0s 55us/sample - loss: 86.2143 - mse: 86.2143\n",
      "Epoch 37/100\n",
      "404/404 [==============================] - 0s 59us/sample - loss: 84.9201 - mse: 84.9201\n",
      "Epoch 38/100\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 85.5213 - mse: 85.5213\n",
      "Epoch 39/100\n",
      "404/404 [==============================] - 0s 57us/sample - loss: 85.1032 - mse: 85.1032\n",
      "Epoch 40/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 84.8884 - mse: 84.8884\n",
      "Epoch 41/100\n",
      "404/404 [==============================] - 0s 61us/sample - loss: 85.0741 - mse: 85.0741\n",
      "Epoch 42/100\n",
      "404/404 [==============================] - 0s 48us/sample - loss: 85.5869 - mse: 85.5869\n",
      "Epoch 43/100\n",
      "404/404 [==============================] - 0s 70us/sample - loss: 85.4651 - mse: 85.4651\n",
      "Epoch 44/100\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 84.8887 - mse: 84.8887\n",
      "Epoch 45/100\n",
      "404/404 [==============================] - 0s 70us/sample - loss: 84.9183 - mse: 84.9183\n",
      "Epoch 46/100\n",
      "404/404 [==============================] - 0s 50us/sample - loss: 85.1288 - mse: 85.1288\n",
      "Epoch 47/100\n",
      "404/404 [==============================] - 0s 55us/sample - loss: 84.8646 - mse: 84.8646\n",
      "Epoch 48/100\n",
      "404/404 [==============================] - 0s 67us/sample - loss: 85.8341 - mse: 85.8341\n",
      "Epoch 49/100\n",
      "404/404 [==============================] - 0s 71us/sample - loss: 85.1375 - mse: 85.1375\n",
      "Epoch 50/100\n",
      "404/404 [==============================] - 0s 81us/sample - loss: 85.7573 - mse: 85.7573\n",
      "Epoch 51/100\n",
      "404/404 [==============================] - 0s 72us/sample - loss: 84.7741 - mse: 84.7741\n",
      "Epoch 52/100\n",
      "404/404 [==============================] - 0s 50us/sample - loss: 84.9535 - mse: 84.9535\n",
      "Epoch 53/100\n",
      "404/404 [==============================] - 0s 49us/sample - loss: 85.1362 - mse: 85.1362\n",
      "Epoch 54/100\n",
      "404/404 [==============================] - 0s 54us/sample - loss: 85.1748 - mse: 85.1748\n",
      "Epoch 55/100\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 84.7255 - mse: 84.7255\n",
      "Epoch 56/100\n",
      "404/404 [==============================] - 0s 73us/sample - loss: 85.3264 - mse: 85.3264\n",
      "Epoch 57/100\n",
      "404/404 [==============================] - 0s 65us/sample - loss: 85.1007 - mse: 85.1007\n",
      "Epoch 58/100\n",
      "404/404 [==============================] - 0s 51us/sample - loss: 85.3335 - mse: 85.3335\n",
      "Epoch 59/100\n",
      "404/404 [==============================] - 0s 45us/sample - loss: 84.9647 - mse: 84.9647\n",
      "Epoch 60/100\n",
      "404/404 [==============================] - 0s 55us/sample - loss: 85.5519 - mse: 85.5519\n",
      "Epoch 61/100\n",
      "404/404 [==============================] - 0s 46us/sample - loss: 85.2854 - mse: 85.2854\n",
      "Epoch 62/100\n",
      "404/404 [==============================] - 0s 51us/sample - loss: 84.9257 - mse: 84.9257\n",
      "Epoch 63/100\n",
      "404/404 [==============================] - 0s 48us/sample - loss: 85.2428 - mse: 85.2428\n",
      "Epoch 64/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 85.6245 - mse: 85.6245\n",
      "Epoch 65/100\n",
      "404/404 [==============================] - 0s 49us/sample - loss: 85.3805 - mse: 85.3805\n",
      "Epoch 66/100\n",
      "404/404 [==============================] - 0s 48us/sample - loss: 84.9869 - mse: 84.9869\n",
      "Epoch 67/100\n",
      "404/404 [==============================] - 0s 46us/sample - loss: 84.9822 - mse: 84.9822\n",
      "Epoch 68/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 85.2501 - mse: 85.2501\n",
      "Epoch 69/100\n",
      "404/404 [==============================] - 0s 48us/sample - loss: 85.0066 - mse: 85.0066\n",
      "Epoch 70/100\n",
      "404/404 [==============================] - 0s 44us/sample - loss: 84.6351 - mse: 84.6351\n",
      "Epoch 71/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 84.8971 - mse: 84.8971\n",
      "Epoch 72/100\n",
      "404/404 [==============================] - 0s 50us/sample - loss: 85.2587 - mse: 85.2587\n",
      "Epoch 73/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 86.2309 - mse: 86.2309\n",
      "Epoch 74/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 85.4435 - mse: 85.4435\n",
      "Epoch 75/100\n",
      "404/404 [==============================] - 0s 46us/sample - loss: 85.2218 - mse: 85.2218\n",
      "Epoch 76/100\n",
      "404/404 [==============================] - 0s 49us/sample - loss: 84.7998 - mse: 84.7998\n",
      "Epoch 77/100\n",
      "404/404 [==============================] - 0s 49us/sample - loss: 85.1119 - mse: 85.1119\n",
      "Epoch 78/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 84.7512 - mse: 84.7512\n",
      "Epoch 79/100\n",
      "404/404 [==============================] - 0s 47us/sample - loss: 86.9366 - mse: 86.9366\n",
      "Epoch 80/100\n",
      "404/404 [==============================] - 0s 48us/sample - loss: 85.2337 - mse: 85.2337\n",
      "Epoch 81/100\n",
      "404/404 [==============================] - 0s 48us/sample - loss: 85.1186 - mse: 85.1186\n",
      "Epoch 82/100\n",
      "404/404 [==============================] - 0s 54us/sample - loss: 84.7064 - mse: 84.7064\n",
      "Epoch 83/100\n",
      "404/404 [==============================] - 0s 48us/sample - loss: 84.7490 - mse: 84.7490\n",
      "Epoch 84/100\n",
      "404/404 [==============================] - 0s 46us/sample - loss: 85.3782 - mse: 85.3782\n",
      "Epoch 85/100\n",
      "404/404 [==============================] - 0s 46us/sample - loss: 85.5090 - mse: 85.5090\n",
      "Epoch 86/100\n",
      "404/404 [==============================] - 0s 44us/sample - loss: 85.1749 - mse: 85.1749\n",
      "Epoch 87/100\n",
      "404/404 [==============================] - 0s 45us/sample - loss: 84.6782 - mse: 84.6782\n",
      "Epoch 88/100\n",
      "404/404 [==============================] - 0s 57us/sample - loss: 84.8500 - mse: 84.8500\n",
      "Epoch 89/100\n",
      "404/404 [==============================] - 0s 39us/sample - loss: 85.2368 - mse: 85.2368\n",
      "Epoch 90/100\n",
      "404/404 [==============================] - 0s 42us/sample - loss: 85.3666 - mse: 85.3666\n",
      "Epoch 91/100\n",
      "404/404 [==============================] - 0s 64us/sample - loss: 86.9404 - mse: 86.9404\n",
      "Epoch 92/100\n",
      "404/404 [==============================] - 0s 57us/sample - loss: 85.0542 - mse: 85.0542\n",
      "Epoch 93/100\n",
      "404/404 [==============================] - 0s 59us/sample - loss: 86.3505 - mse: 86.3505\n",
      "Epoch 94/100\n",
      "404/404 [==============================] - 0s 44us/sample - loss: 85.2151 - mse: 85.2151\n",
      "Epoch 95/100\n",
      "404/404 [==============================] - 0s 40us/sample - loss: 84.7211 - mse: 84.7211\n",
      "Epoch 96/100\n",
      "404/404 [==============================] - 0s 42us/sample - loss: 85.1922 - mse: 85.1922\n",
      "Epoch 97/100\n",
      "404/404 [==============================] - 0s 38us/sample - loss: 85.5947 - mse: 85.5947\n",
      "Epoch 98/100\n",
      "404/404 [==============================] - 0s 41us/sample - loss: 84.9850 - mse: 84.9850\n",
      "Epoch 99/100\n",
      "404/404 [==============================] - 0s 45us/sample - loss: 85.2746 - mse: 85.2746\n",
      "Epoch 100/100\n",
      "404/404 [==============================] - 0s 46us/sample - loss: 85.3178 - mse: 85.3178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1410b4f98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "102/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 909us/sample - loss: 137.8733 - mse: 87.6771\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'mse']\n",
      "[87.67707764868642, 87.677086]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  87.67707764868642\n",
      "mse:  87.677086\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results[0])\n",
    "print('mse: ', results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP for classification tasks\n",
    "- When the target (**y**) is discrete (categorical)\n",
    "- For loss function, cross-entropy is used and for evaluation metric, accuracy is commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = whole_data.data\n",
    "y_data = whole_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size = 0.3, random_state = 7) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "- Breast cancer dataset has total 569 data instances (212 malign, 357 benign instances)\n",
    "- 30 attributes (features) to predict the binary class (M/B)\n",
    "- Doc: http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creating a model\n",
    "- Same with regression model at the outset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Adding layers\n",
    "- Keras layers can be **added** to the model\n",
    "- Adding layers are like stacking lego blocks one by one\n",
    "- It should be noted that as this is a classification problem, sigmoid layer (softmax for multi-class problems) should be added\n",
    "- Doc: https://keras.io/layers/core/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras model with two hidden layer with 10 neurons each \n",
    "model.add(Dense(10, input_shape = (30,)))    # Input layer => input_shape should be explicitly designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))                         # Hidden layer => only output dimension should be designated\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1))                          # Output layer => output dimension = 1 since it is regression problem\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "##To Destroys the current TF graph and creates a new one:\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is equivalent to the above code block\n",
    "model.add(Dense(10, input_shape = (30,), activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(10, activation = 'sigmoid'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-2. Model compile\n",
    "- Keras model should be \"compiled\" prior to training\n",
    "- Types of loss (function) and optimizer should be designated\n",
    "    - Doc (optimizers): https://keras.io/optimizers/\n",
    "    - Doc (losses): https://keras.io/losses/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr = 0.01)    # stochastic gradient descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = sgd, loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                310       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Training\n",
    "- Training the model with training data provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 398 samples\n",
      "Epoch 1/100\n",
      "398/398 [==============================] - 0s 1ms/sample - loss: 0.7038 - accuracy: 0.3945\n",
      "Epoch 2/100\n",
      "398/398 [==============================] - 0s 59us/sample - loss: 0.6997 - accuracy: 0.3945\n",
      "Epoch 3/100\n",
      "398/398 [==============================] - 0s 62us/sample - loss: 0.6960 - accuracy: 0.3945\n",
      "Epoch 4/100\n",
      "398/398 [==============================] - 0s 70us/sample - loss: 0.6929 - accuracy: 0.5352\n",
      "Epoch 5/100\n",
      "398/398 [==============================] - 0s 64us/sample - loss: 0.6902 - accuracy: 0.6055\n",
      "Epoch 6/100\n",
      "398/398 [==============================] - 0s 54us/sample - loss: 0.6877 - accuracy: 0.6055\n",
      "Epoch 7/100\n",
      "398/398 [==============================] - 0s 41us/sample - loss: 0.6857 - accuracy: 0.6055\n",
      "Epoch 8/100\n",
      "398/398 [==============================] - 0s 53us/sample - loss: 0.6838 - accuracy: 0.6055\n",
      "Epoch 9/100\n",
      "398/398 [==============================] - 0s 43us/sample - loss: 0.6822 - accuracy: 0.6055\n",
      "Epoch 10/100\n",
      "398/398 [==============================] - 0s 38us/sample - loss: 0.6808 - accuracy: 0.6055\n",
      "Epoch 11/100\n",
      "398/398 [==============================] - 0s 58us/sample - loss: 0.6795 - accuracy: 0.6055\n",
      "Epoch 12/100\n",
      "398/398 [==============================] - 0s 47us/sample - loss: 0.6784 - accuracy: 0.6055\n",
      "Epoch 13/100\n",
      "398/398 [==============================] - 0s 55us/sample - loss: 0.6775 - accuracy: 0.6055\n",
      "Epoch 14/100\n",
      "398/398 [==============================] - 0s 40us/sample - loss: 0.6767 - accuracy: 0.6055\n",
      "Epoch 15/100\n",
      "398/398 [==============================] - 0s 52us/sample - loss: 0.6760 - accuracy: 0.6055\n",
      "Epoch 16/100\n",
      "398/398 [==============================] - 0s 58us/sample - loss: 0.6753 - accuracy: 0.6055\n",
      "Epoch 17/100\n",
      "398/398 [==============================] - 0s 59us/sample - loss: 0.6748 - accuracy: 0.6055\n",
      "Epoch 18/100\n",
      "398/398 [==============================] - 0s 55us/sample - loss: 0.6742 - accuracy: 0.6055\n",
      "Epoch 19/100\n",
      "398/398 [==============================] - 0s 51us/sample - loss: 0.6738 - accuracy: 0.6055\n",
      "Epoch 20/100\n",
      "398/398 [==============================] - 0s 49us/sample - loss: 0.6734 - accuracy: 0.6055\n",
      "Epoch 21/100\n",
      "398/398 [==============================] - 0s 60us/sample - loss: 0.6731 - accuracy: 0.6055\n",
      "Epoch 22/100\n",
      "398/398 [==============================] - 0s 46us/sample - loss: 0.6728 - accuracy: 0.6055\n",
      "Epoch 23/100\n",
      "398/398 [==============================] - 0s 45us/sample - loss: 0.6725 - accuracy: 0.6055\n",
      "Epoch 24/100\n",
      "398/398 [==============================] - 0s 51us/sample - loss: 0.6725 - accuracy: 0.6055\n",
      "Epoch 25/100\n",
      "398/398 [==============================] - 0s 47us/sample - loss: 0.6722 - accuracy: 0.6055\n",
      "Epoch 26/100\n",
      "398/398 [==============================] - 0s 48us/sample - loss: 0.6719 - accuracy: 0.6055\n",
      "Epoch 27/100\n",
      "398/398 [==============================] - 0s 71us/sample - loss: 0.6718 - accuracy: 0.6055\n",
      "Epoch 28/100\n",
      "398/398 [==============================] - 0s 93us/sample - loss: 0.6717 - accuracy: 0.6055\n",
      "Epoch 29/100\n",
      "398/398 [==============================] - 0s 71us/sample - loss: 0.6715 - accuracy: 0.6055\n",
      "Epoch 30/100\n",
      "398/398 [==============================] - 0s 77us/sample - loss: 0.6714 - accuracy: 0.6055\n",
      "Epoch 31/100\n",
      "398/398 [==============================] - 0s 59us/sample - loss: 0.6713 - accuracy: 0.6055\n",
      "Epoch 32/100\n",
      "398/398 [==============================] - 0s 69us/sample - loss: 0.6714 - accuracy: 0.6055\n",
      "Epoch 33/100\n",
      "398/398 [==============================] - 0s 58us/sample - loss: 0.6711 - accuracy: 0.6055\n",
      "Epoch 34/100\n",
      "398/398 [==============================] - 0s 58us/sample - loss: 0.6710 - accuracy: 0.6055\n",
      "Epoch 35/100\n",
      "398/398 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.56 - 0s 68us/sample - loss: 0.6711 - accuracy: 0.6055\n",
      "Epoch 36/100\n",
      "398/398 [==============================] - 0s 60us/sample - loss: 0.6709 - accuracy: 0.6055\n",
      "Epoch 37/100\n",
      "398/398 [==============================] - 0s 74us/sample - loss: 0.6709 - accuracy: 0.6055\n",
      "Epoch 38/100\n",
      "398/398 [==============================] - 0s 69us/sample - loss: 0.6709 - accuracy: 0.6055\n",
      "Epoch 39/100\n",
      "398/398 [==============================] - 0s 67us/sample - loss: 0.6708 - accuracy: 0.6055\n",
      "Epoch 40/100\n",
      "398/398 [==============================] - 0s 91us/sample - loss: 0.6707 - accuracy: 0.6055\n",
      "Epoch 41/100\n",
      "398/398 [==============================] - 0s 81us/sample - loss: 0.6708 - accuracy: 0.6055\n",
      "Epoch 42/100\n",
      "398/398 [==============================] - 0s 85us/sample - loss: 0.6707 - accuracy: 0.6055\n",
      "Epoch 43/100\n",
      "398/398 [==============================] - 0s 79us/sample - loss: 0.6707 - accuracy: 0.6055\n",
      "Epoch 44/100\n",
      "398/398 [==============================] - 0s 66us/sample - loss: 0.6707 - accuracy: 0.6055\n",
      "Epoch 45/100\n",
      "398/398 [==============================] - 0s 79us/sample - loss: 0.6706 - accuracy: 0.6055\n",
      "Epoch 46/100\n",
      "398/398 [==============================] - 0s 63us/sample - loss: 0.6706 - accuracy: 0.6055\n",
      "Epoch 47/100\n",
      "398/398 [==============================] - 0s 54us/sample - loss: 0.6706 - accuracy: 0.6055\n",
      "Epoch 48/100\n",
      "398/398 [==============================] - 0s 79us/sample - loss: 0.6705 - accuracy: 0.6055\n",
      "Epoch 49/100\n",
      "398/398 [==============================] - 0s 59us/sample - loss: 0.6706 - accuracy: 0.6055\n",
      "Epoch 50/100\n",
      "398/398 [==============================] - 0s 85us/sample - loss: 0.6706 - accuracy: 0.6055\n",
      "Epoch 51/100\n",
      "398/398 [==============================] - 0s 102us/sample - loss: 0.6705 - accuracy: 0.6055\n",
      "Epoch 52/100\n",
      "398/398 [==============================] - 1s 2ms/sample - loss: 0.6705 - accuracy: 0.6055\n",
      "Epoch 53/100\n",
      "398/398 [==============================] - 0s 88us/sample - loss: 0.6704 - accuracy: 0.6055\n",
      "Epoch 54/100\n",
      "398/398 [==============================] - 0s 118us/sample - loss: 0.6705 - accuracy: 0.6055\n",
      "Epoch 55/100\n",
      "398/398 [==============================] - 0s 96us/sample - loss: 0.6705 - accuracy: 0.6055\n",
      "Epoch 56/100\n",
      "398/398 [==============================] - 0s 69us/sample - loss: 0.6704 - accuracy: 0.6055\n",
      "Epoch 57/100\n",
      "398/398 [==============================] - 0s 61us/sample - loss: 0.6704 - accuracy: 0.6055\n",
      "Epoch 58/100\n",
      "398/398 [==============================] - 0s 71us/sample - loss: 0.6704 - accuracy: 0.6055\n",
      "Epoch 59/100\n",
      "398/398 [==============================] - 0s 68us/sample - loss: 0.6704 - accuracy: 0.6055\n",
      "Epoch 60/100\n",
      "398/398 [==============================] - 0s 76us/sample - loss: 0.6704 - accuracy: 0.6055\n",
      "Epoch 61/100\n",
      "398/398 [==============================] - 0s 68us/sample - loss: 0.6703 - accuracy: 0.6055\n",
      "Epoch 62/100\n",
      "398/398 [==============================] - 0s 72us/sample - loss: 0.6703 - accuracy: 0.6055\n",
      "Epoch 63/100\n",
      "398/398 [==============================] - 0s 59us/sample - loss: 0.6703 - accuracy: 0.6055\n",
      "Epoch 64/100\n",
      "398/398 [==============================] - 0s 54us/sample - loss: 0.6703 - accuracy: 0.6055\n",
      "Epoch 65/100\n",
      "398/398 [==============================] - 0s 62us/sample - loss: 0.6703 - accuracy: 0.6055\n",
      "Epoch 66/100\n",
      "398/398 [==============================] - 0s 73us/sample - loss: 0.6704 - accuracy: 0.6055\n",
      "Epoch 67/100\n",
      "398/398 [==============================] - 0s 60us/sample - loss: 0.6704 - accuracy: 0.6055\n",
      "Epoch 68/100\n",
      "398/398 [==============================] - 0s 66us/sample - loss: 0.6703 - accuracy: 0.6055\n",
      "Epoch 69/100\n",
      "398/398 [==============================] - 0s 53us/sample - loss: 0.6703 - accuracy: 0.6055\n",
      "Epoch 70/100\n",
      "398/398 [==============================] - 0s 67us/sample - loss: 0.6703 - accuracy: 0.6055\n",
      "Epoch 71/100\n",
      "398/398 [==============================] - 0s 54us/sample - loss: 0.6702 - accuracy: 0.6055\n",
      "Epoch 72/100\n",
      "398/398 [==============================] - 0s 66us/sample - loss: 0.6702 - accuracy: 0.6055\n",
      "Epoch 73/100\n",
      "398/398 [==============================] - 0s 52us/sample - loss: 0.6703 - accuracy: 0.6055\n",
      "Epoch 74/100\n",
      "398/398 [==============================] - 0s 66us/sample - loss: 0.6703 - accuracy: 0.6055\n",
      "Epoch 75/100\n",
      "398/398 [==============================] - 0s 58us/sample - loss: 0.6702 - accuracy: 0.6055\n",
      "Epoch 76/100\n",
      "398/398 [==============================] - 0s 83us/sample - loss: 0.6702 - accuracy: 0.6055\n",
      "Epoch 77/100\n",
      "398/398 [==============================] - 0s 75us/sample - loss: 0.6702 - accuracy: 0.6055\n",
      "Epoch 78/100\n",
      "398/398 [==============================] - 0s 65us/sample - loss: 0.6702 - accuracy: 0.6055\n",
      "Epoch 79/100\n",
      "398/398 [==============================] - 0s 77us/sample - loss: 0.6701 - accuracy: 0.6055\n",
      "Epoch 80/100\n",
      "398/398 [==============================] - 0s 76us/sample - loss: 0.6702 - accuracy: 0.6055\n",
      "Epoch 81/100\n",
      "398/398 [==============================] - 0s 62us/sample - loss: 0.6701 - accuracy: 0.6055\n",
      "Epoch 82/100\n",
      "398/398 [==============================] - 0s 54us/sample - loss: 0.6702 - accuracy: 0.6055\n",
      "Epoch 83/100\n",
      "398/398 [==============================] - 0s 58us/sample - loss: 0.6701 - accuracy: 0.6055\n",
      "Epoch 84/100\n",
      "398/398 [==============================] - 0s 65us/sample - loss: 0.6701 - accuracy: 0.6055\n",
      "Epoch 85/100\n",
      "398/398 [==============================] - 0s 53us/sample - loss: 0.6701 - accuracy: 0.6055\n",
      "Epoch 86/100\n",
      "398/398 [==============================] - 0s 58us/sample - loss: 0.6701 - accuracy: 0.6055\n",
      "Epoch 87/100\n",
      "398/398 [==============================] - 0s 62us/sample - loss: 0.6701 - accuracy: 0.6055\n",
      "Epoch 88/100\n",
      "398/398 [==============================] - 0s 82us/sample - loss: 0.6701 - accuracy: 0.6055\n",
      "Epoch 89/100\n",
      "398/398 [==============================] - 0s 65us/sample - loss: 0.6701 - accuracy: 0.6055\n",
      "Epoch 90/100\n",
      "398/398 [==============================] - 0s 68us/sample - loss: 0.6700 - accuracy: 0.6055\n",
      "Epoch 91/100\n",
      "398/398 [==============================] - 0s 78us/sample - loss: 0.6702 - accuracy: 0.6055\n",
      "Epoch 92/100\n",
      "398/398 [==============================] - 0s 84us/sample - loss: 0.6700 - accuracy: 0.6055\n",
      "Epoch 93/100\n",
      "398/398 [==============================] - 0s 82us/sample - loss: 0.6701 - accuracy: 0.6055\n",
      "Epoch 94/100\n",
      "398/398 [==============================] - 0s 63us/sample - loss: 0.6701 - accuracy: 0.6055\n",
      "Epoch 95/100\n",
      "398/398 [==============================] - 0s 70us/sample - loss: 0.6700 - accuracy: 0.6055\n",
      "Epoch 96/100\n",
      "398/398 [==============================] - 0s 87us/sample - loss: 0.6700 - accuracy: 0.6055\n",
      "Epoch 97/100\n",
      "398/398 [==============================] - 0s 61us/sample - loss: 0.6700 - accuracy: 0.6055\n",
      "Epoch 98/100\n",
      "398/398 [==============================] - 0s 60us/sample - loss: 0.6700 - accuracy: 0.6055\n",
      "Epoch 99/100\n",
      "398/398 [==============================] - 0s 49us/sample - loss: 0.6700 - accuracy: 0.6055\n",
      "Epoch 100/100\n",
      "398/398 [==============================] - 0s 48us/sample - loss: 0.6699 - accuracy: 0.6055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x144b185c0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluation\n",
    "- Keras model can be evaluated with evaluate() function\n",
    "- Evaluation results are contained in a list\n",
    "    - Doc (metrics): https://keras.io/metrics/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "171/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 665us/sample - loss: 0.6481 - accuracy: 0.6784\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['loss', 'accuracy']\n",
      "[0.6391866688142743, 0.67836255]\n"
     ]
    }
   ],
   "source": [
    "print(model.metrics_names)     # list of metric names the model is employing\n",
    "print(results)                 # actual figure of metrics computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.6391866688142743\n",
      "accuracy:  0.67836255\n"
     ]
    }
   ],
   "source": [
    "print('loss: ', results[0])\n",
    "print('accuracy: ', results[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
